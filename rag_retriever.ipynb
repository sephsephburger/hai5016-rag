{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c19cb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e442755",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  print(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
    "\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4eb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"SUPABASE_CONNECTION_STRING\"):\n",
    "    os.environ[\"SUPABASE_CONNECTION_STRING\"] = getpass.getpass(\"Enter connection string for Supabase: \")\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"lilianweng_blog\",\n",
    "    connection=os.environ[\"SUPABASE_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c0bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75fa739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258b3d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (ab63f507-4653-4cfb-bdf4-5ce142b28bca)\n",
      " Call ID: ab63f507-4653-4cfb-bdf4-5ce142b28bca\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17734}\n",
      "Content: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (97aa23e5-f81a-41a6-a29d-b04ffa697b62)\n",
      " Call ID: 97aa23e5-f81a-41a6-a29d-b04ffa697b62\n",
      "  Args:\n",
      "    query: extensions of LLM-based task decomposition methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17352}\n",
      "Content: Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
      "\n",
      "The system comprises of 4 stages:\n",
      "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
      "Instruction:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'The standard methods for Task Decomposition include using a Large Language Model (LLM) with simple prompting (e.g., \"Steps for XYZ.\" or \"What are the subgoals for achieving XYZ?\"), providing task-specific instructions (e.g., \"Write a story outline.\" for writing a novel), or relying on human inputs.\\n\\nCommon extensions of these methods include:\\n*   **Few-shot examples:** Guiding the LLM to perform task parsing and planning using a few illustrative examples.\\n*   **LLM+P (LLM + Planner):** This approach involves an LLM translating a problem into \"Problem PDDL\" (Planning Domain Definition Language), requesting a classical planner to generate a PDDL plan, and then translating the plan back into natural language. This method outsources the planning step to an external tool and is common in certain robotic setups.', 'extras': {'signature': 'CoQKAXLI2nzfRQzboSaVzEYqlCN0UorwD/aNi4mEjMNPgVuIHx9nOOj4mjC0vFaQTshqdk7H9euC50Pqg5YLrpuCaHfeCzvP1IWbWM2zBVTX10omcB4x80O0tK9jV24scIMZKzaCmGsoXRqo66PMwtb3DXlRDPXpOTrm75UMm59JiAKxMXQFJwRsSGfn/yCM6zE2un1E/NulLeOIQjYhKGWzBXWoPGlAYb/Xiuw2+eMEIkEf5BLbAKKSOCwX6QmuJTLAsnqolZYUaiYfmwoz/4Ul25/6Oua9XT0lycKD3LRRSDxJrnn0EoZbwmg8mYw4OMAj8lZKx0EGSzaty6AZV9uKs9ZzuaybKFZZpQKY2ept9TyEuuII/B8n7ppzzX0+o3Q61JVT0HUFLVamWjsaBJctza77SUm9FJ4R+OxjvkX8KYcAJo/1/RxBdXuK2Z2Cl/zltk3zSC27gM4atHsCF6wMlT1FCfPyAt8+WlqW582MFr7W7+IJMqiYlZXBpl36ShwEI+foqapAxc9gxXvJrxWeegMTXzN2VG8ldGzTDoPJoTIR4zVZkZ+NS3EhfA6koG8Y9tUM5+qQOlviXqbFBP7FBuhqqo/Nh3tDOFQbX2EaP7ziEpXHXHWZbB33612QAeIRfi2NKQF3U3IqSlLJL4NRBqG3OmFNvrXoQ0XQcDVZ+UcnSlGkm3gSJ8QXucy6URxJVN3DWB8IAIHRWv7WpF7sNXfX1rkQearmWIJxuvJu1alHEPvnrowDmvrXRdnw0wt6azZxsYHO1CJBBS5UrQLVvhO/wn1IIIJ3oFDyJqy9NgcMeC3+k6EeOLJl+Y+17WN213+t7xLWZph7NYdAR3zE5DygUVsZNzgtZ4RvXR6uHJYEaj/3d9IFHldS8/LaJm3rMMeruMiSs5VAhbXZtKigUBLXvNgPSGqXrPRu/a7X6EfEwK0BzKOtfD0RAqDmv26hzBobXA8GQqIp/FfdDWC86e/lZ9jm6jBOSt3vVb1YIbBMMByv1VTbKFP1RocBacOpF121Mf12Ds1BRp6sP8P4B1L3ZIDbRTj44Gjp6YoZRmFrQhKFLKKeMEQBx9wXxDDEMWYOwCynaTMLCS0+s7M348PSbjlPgFBgSBuDJNPY3HBnaqup2UlxMX7AjP4FyS8ioeTj9q9qwpH0OI/ioEuXSAUDQvxG6DAeDU5iKo8d13bLWFaiAE0JeGF8+bnSO21KgKePLyh9hIO8kzm07P0MzEIOw9Ad7zIBrimZhnPhq/mjWUFJAOaM92rByiKGkKXlQ5ClunRVYFqloEXhm1cK3yfiMHuKjxwm8SAhjigDp6c/wWt6W0qC/+HW5/7oCt6YiVuGeBvBHESXddjeATyNF/qG8nIRilsIdzWcVLh49+8lm+ZQeyexJby1dXBwt/kRG0eEPyMDtq7qp3wDcYUe4emHiVIUbPF5Z/o1qjx9wcBxI2dinCSfv1xCJM5I2BGcO6Q0gDdiS/d6NtDxU9thYLd8ILjueXTR5XIXHqeOiVmyEowobXkZLRH1XZ4KquKd7rv5mrgIllxkG202cazfiLG2oAqbGRgqTcuzgfpirEMucWX/Ljr5xNj6qzH3Nvk+AQJpPVNbp02DJcBrKDA/BZySiK8v4bFZ3HynvUm2PS5BvEElkSAvFsnWNv2O1NwrKFKGaGV++O6r4/E6H/2hrLIF0WZ82yh/G3wAAb5EYqvuTlc6'}}]\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    last_message = event[\"messages\"][-1]\n",
    "    last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec655a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The standard methods for Task Decomposition include using a Large Language Model (LLM) with simple prompting (e.g., \"Steps for XYZ.\" or \"What are the subgoals for achieving XYZ?\"), providing task-specific instructions (e.g., \"Write a story outline.\" for writing a novel), or relying on human inputs.\n",
       "\n",
       "Common extensions of these methods include:\n",
       "*   **Few-shot examples:** Guiding the LLM to perform task parsing and planning using a few illustrative examples.\n",
       "*   **LLM+P (LLM + Planner):** This approach involves an LLM translating a problem into \"Problem PDDL\" (Planning Domain Definition Language), requesting a classical planner to generate a PDDL plan, and then translating the plan back into natural language. This method outsources the planning step to an external tool and is common in certain robotic setups."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render the agent's last message as Markdown in the Jupyter output\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(last_message.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41a669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hai5016-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
